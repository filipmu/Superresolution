{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a video dataset to do better training\n",
    "- higher resolution than used in research\n",
    "\n",
    "### super 8 look https://www.youtube.com/watch?v=7Q5UZmwxIXo\n",
    "- low focus (diffusion and blur)\n",
    "- low contrast\n",
    "- camera is more shakey on home movies\n",
    "- high depth of field everything is sharp\n",
    "- 4x3\n",
    "- film grain\n",
    "- color changes\n",
    "\n",
    "### VCR look\n",
    "- jitter on scan lines - see http://www.avisynth.nl/users/vcmohan/DeJitter/DeJitter.htm\n",
    "- chroma issues https://forum.videohelp.com/threads/397928-Imrpove-old-video-recorded-by-a-bad-camera?s=0a1230911434e7442d05b6b6cee8e6d2\n",
    "\n",
    "## use images of related material to train superres\n",
    "- family photos to train for family videos\n",
    "\n",
    "\n",
    "## other datasets\n",
    "wget https://cv.snu.ac.kr/research/EDSR/Flickr2K.tar\n",
    "tar -xvf Flickr2K.tar\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this vimeo downloader: https://github.com/r0oth3x49/vimeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vimeo_dl as vimeo\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vimeo.com/140816903\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = vimeo.new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Just For Men - Foolproof', '00:31')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.title, video.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal:mp4@1162x720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD/superres\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_list_fn = \"/media/SSD/superres/pytorch-vdsr/data/original_video_list.txt\"\n",
    "path = \"/media/SSD/superres/video_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vid_list_fn) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad=0\n",
    "rescount=292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [39:50<00:00,  3.98s/it]  \n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(content[601:1201]):\n",
    "    try:\n",
    "        video = vimeo.new(url)\n",
    "        streams = video.streams\n",
    "    except TypeError:\n",
    "        #print(\"Bad URL:\", url)\n",
    "        bad=bad+1\n",
    "    else:        \n",
    "        \n",
    "        for s in streams:\n",
    "            if s.extension == 'mp4' and s.resolution == '1280x720' :\n",
    "                \n",
    "                filename = path + url[url.find('/',8)+1:]+\".mp4\"\n",
    "                #print(url,s.resolution,\"->\",filename)\n",
    "                s.download(filename,quiet=True)\n",
    "                rescount=rescount+1\n",
    "    \n",
    "    #sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_list_fn = \"/media/SSD/superres/list of vimeo movies\"\n",
    "path = \"/media/SSD/superres/video_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vid_list_fn) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad=0\n",
    "rescount=620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [02:36<00:10, 10.46s/it]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'video_id' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7497c259f3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvimeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/SSD/conda_env/superres/lib/python3.8/site-packages/vimeo_dl/vimeo.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(url, basic, data, size, callback)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"internal\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvimeo_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInternVimeo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mVimeo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mVimeo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/SSD/conda_env/superres/lib/python3.8/site-packages/vimeo_dl/vimeo_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInternVimeo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/SSD/conda_env/superres/lib/python3.8/site-packages/vimeo_dl/vimeo_shared.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, basic, data, size, callback)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_vid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_json_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_config_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/SSD/conda_env/superres/lib/python3.8/site-packages/vimeo_dl/vimeo_shared.py\u001b[0m in \u001b[0;36mextract_vid\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_json_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'video_id' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for url in tqdm(content):\n",
    "    try:\n",
    "        video = vimeo.new(url)\n",
    "        streams = video.streams\n",
    "    except TypeError:\n",
    "        #print(\"Bad URL:\", url)\n",
    "        bad=bad+1\n",
    "    else:        \n",
    "        \n",
    "        for s in streams:\n",
    "            if s.extension == 'mp4' and s.resolution == '1280x720' :\n",
    "                \n",
    "                filename = path + url[url.find('/',8)+1:]+\".mp4\"\n",
    "                #print(url,s.resolution,\"->\",filename)\n",
    "                s.download(filename,quiet=True)\n",
    "                rescount=rescount+1\n",
    "    \n",
    "    #sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://vimeo.com/68445748',\n",
       " 'https://vimeo.com/178858950',\n",
       " 'https://vimeo.com/420951241',\n",
       " 'https://vimeo.com/137712021',\n",
       " 'https://vimeo.com/292184739',\n",
       " 'https://vimeo.com/89190137',\n",
       " 'https://vimeo.com/55172677',\n",
       " 'https://vimeo.com/182932029',\n",
       " 'https://vimeo.com/10450125',\n",
       " 'https://vimeo.com/13181904',\n",
       " 'https://vimeo.com/17851496',\n",
       " 'https://vimeo.com/44060692',\n",
       " 'https://vimeo.com/120061340',\n",
       " 'https://vimeo.com/178500853',\n",
       " 'https://vimeo.com/269305059',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the load for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess video from wmv to mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ffmpeg -i '/home/filip/Videos/1987 first video making muffins.wmv'  -c:v libx264 -crf 23 -c:a aac -strict -2 -q:a 100 '/media/SSD/superres/1987 first video making muffins.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /media/SSD/superres/Zooming-Slow-Mo-CVPR-2020/codes/video_to_zsm.py --video /media/SSD/superres/snip.mp4  --model /media/SSD/superres/model/xiang2020zooming.pth --output /media/SSD/superres/muffins_test.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD/superres\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deinterlace\n",
    "https://video.stackexchange.com/questions/17396/how-to-deinterlacing-with-ffmpeg\n",
    "https://macilatthefront.blogspot.com/2017/04/deinterlacing-hd-footage-without-losing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/media/SSD/superres/pytorch-vdsr/')\n",
    "#import vdsr\n",
    "from vdsr import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data loader\n",
    "- see https://github.com/2KangHo/vdsr_pytorch/blob/master/data.py\n",
    "- see https://github.com/2KangHo/vdsr_pytorch/blob/master/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import torchvision as vision\n",
    "\n",
    "\n",
    "toPIL = vision.transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def noisy(img, std=3.0):\n",
    "    mean = 0.0\n",
    "    gauss = np.random.normal(mean, std, (img.height, img.width, 3))\n",
    "    # noisy = np.clip(np.uint8(img + gauss), 0, 255)\n",
    "    noisy = np.uint8(img + gauss)\n",
    "    return noisy\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('YCbCr')\n",
    "    return img\n",
    "\n",
    "\n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, input_transform=None, target_transform=None, add_noise=None, noise_std=3.0):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x)\n",
    "                                for x in listdir(image_dir) if is_image_file(x)]\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "        if self.input_transform:\n",
    "            if self.add_noise:\n",
    "                input = noisy(input, self.noise_std)\n",
    "                input = toPIL(input)\n",
    "            input = self.input_transform(input)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize, Grayscale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "\n",
    "def input_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        Grayscale(num_output_channels=1),\n",
    "        CenterCrop(crop_size),\n",
    "        Resize((crop_size//upscale_factor, crop_size//upscale_factor)),\n",
    "        Resize((crop_size, crop_size)),        \n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def target_transform(crop_size):\n",
    "    return Compose([\n",
    "        Grayscale(num_output_channels=1),\n",
    "        CenterCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_training_set(data_dir, crop_size, upscale_factor, add_noise=None, noise_std=3.0):\n",
    "    \n",
    "    cropsize = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "\n",
    "    return DatasetFromFolder(data_dir,\n",
    "                             input_transform=input_transform(\n",
    "                                 cropsize, upscale_factor),\n",
    "                             target_transform=target_transform(cropsize),\n",
    "                             add_noise=add_noise,\n",
    "                             noise_std=noise_std)\n",
    "\n",
    "\n",
    "def get_validation_set(data_dir, crop_size, upscale_factor):\n",
    "    \n",
    "    cropsize = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "\n",
    "    return DatasetFromFolder(data_dir,\n",
    "                             input_transform=input_transform(\n",
    "                                 cropsize, upscale_factor),\n",
    "                             target_transform=target_transform(cropsize))\n",
    "\n",
    "\n",
    "def get_test_set(data_dir, crop_size, upscale_factor):\n",
    "\n",
    "    cropsize = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "\n",
    "    return DatasetFromFolder(data_dir,\n",
    "                             input_transform=input_transform(\n",
    "                                 cropsize, upscale_factor),\n",
    "                             target_transform=target_transform(cropsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/media/SSD/fastai_data/pets/oxford-iiit-pet/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_training_set(data_dir=train_dir, crop_size=256,\n",
    "            upscale_factor=2,add_noise=False, noise_std=3.0)\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=0, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#model = Net()\n",
    "criterion = nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"/media/SSD/superres/pytorch-vdsr/model/model_epoch_50.pth\")[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 0.1\n",
    "lr_step = 5\n",
    "gradient_clip = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=init_lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // lr_step))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch):\n",
    "    model_out_path = \"checkpoint/\" + \"model_epoch_{}.pth\".format(epoch)\n",
    "    state = {\"epoch\": epoch ,\"model\": model}\n",
    "    if not os.path.exists(\"checkpoint/\"):\n",
    "        os.makedirs(\"checkpoint/\")\n",
    "\n",
    "    torch.save(state, model_out_path)\n",
    "\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data_loader, optimizer, model, criterion, epoch):\n",
    "    lr = adjust_learning_rate(optimizer, epoch-1)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "    print(\"Epoch = {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\n",
    "\n",
    "        \n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        loss = criterion(model(input), target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        nn.utils.clip_grad_norm(model.parameters(),gradient_clip) \n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration%10 == 0:\n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-25f571245f6d>:21: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(),gradient_clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](10/462): Loss: 1332.9090576172\n",
      "===> Epoch[1](20/462): Loss: 1218.9575195312\n",
      "===> Epoch[1](30/462): Loss: 1339.7012939453\n",
      "===> Epoch[1](40/462): Loss: 2574.2861328125\n",
      "===> Epoch[1](50/462): Loss: 1563.3532714844\n",
      "===> Epoch[1](60/462): Loss: 1126.9069824219\n",
      "===> Epoch[1](70/462): Loss: 771.7797851562\n",
      "===> Epoch[1](80/462): Loss: 911.9238281250\n",
      "===> Epoch[1](90/462): Loss: 1487.5745849609\n",
      "===> Epoch[1](100/462): Loss: 1496.0246582031\n",
      "===> Epoch[1](110/462): Loss: 1133.2005615234\n",
      "===> Epoch[1](120/462): Loss: 1124.4964599609\n",
      "===> Epoch[1](130/462): Loss: 754.0661621094\n",
      "===> Epoch[1](140/462): Loss: 1811.2097167969\n",
      "===> Epoch[1](150/462): Loss: 2122.0517578125\n",
      "===> Epoch[1](160/462): Loss: 1187.7091064453\n",
      "===> Epoch[1](170/462): Loss: 764.3685913086\n",
      "===> Epoch[1](180/462): Loss: 1292.7869873047\n",
      "===> Epoch[1](190/462): Loss: 1626.5283203125\n",
      "===> Epoch[1](200/462): Loss: 774.4918212891\n",
      "===> Epoch[1](210/462): Loss: 1011.1511840820\n",
      "===> Epoch[1](220/462): Loss: 1241.6042480469\n",
      "===> Epoch[1](230/462): Loss: 1483.8210449219\n",
      "===> Epoch[1](240/462): Loss: 2088.0266113281\n",
      "===> Epoch[1](250/462): Loss: 1080.2432861328\n",
      "===> Epoch[1](260/462): Loss: 1248.4798583984\n",
      "===> Epoch[1](270/462): Loss: 818.3555297852\n",
      "===> Epoch[1](280/462): Loss: 1463.4515380859\n",
      "===> Epoch[1](290/462): Loss: 1462.8315429688\n",
      "===> Epoch[1](300/462): Loss: 1298.8784179688\n",
      "===> Epoch[1](310/462): Loss: 1234.3261718750\n",
      "===> Epoch[1](320/462): Loss: 1513.4093017578\n",
      "===> Epoch[1](330/462): Loss: 735.6424560547\n",
      "===> Epoch[1](340/462): Loss: 1395.1157226562\n",
      "===> Epoch[1](350/462): Loss: 1197.2990722656\n",
      "===> Epoch[1](360/462): Loss: 1977.6350097656\n",
      "===> Epoch[1](370/462): Loss: 1257.6923828125\n",
      "===> Epoch[1](380/462): Loss: 1146.1021728516\n",
      "===> Epoch[1](390/462): Loss: 1659.2910156250\n",
      "===> Epoch[1](400/462): Loss: 1707.4182128906\n",
      "===> Epoch[1](410/462): Loss: 1087.7712402344\n",
      "===> Epoch[1](420/462): Loss: 1490.8437500000\n",
      "===> Epoch[1](430/462): Loss: 1008.3988037109\n",
      "===> Epoch[1](440/462): Loss: 1297.1879882812\n",
      "===> Epoch[1](450/462): Loss: 1077.1596679688\n",
      "===> Epoch[1](460/462): Loss: 1747.0690917969\n",
      "Checkpoint saved to checkpoint/model_epoch_1.pth\n",
      "Epoch = 2, lr = 0.1\n",
      "===> Epoch[2](10/462): Loss: 682.0222167969\n",
      "===> Epoch[2](20/462): Loss: 1419.8576660156\n",
      "===> Epoch[2](30/462): Loss: 1263.3519287109\n",
      "===> Epoch[2](40/462): Loss: 1718.0567626953\n",
      "===> Epoch[2](50/462): Loss: 1476.8242187500\n",
      "===> Epoch[2](60/462): Loss: 911.4352416992\n",
      "===> Epoch[2](70/462): Loss: 1079.3829345703\n",
      "===> Epoch[2](80/462): Loss: 1164.3255615234\n",
      "===> Epoch[2](90/462): Loss: 1359.9482421875\n",
      "===> Epoch[2](100/462): Loss: 1031.8630371094\n",
      "===> Epoch[2](110/462): Loss: 1920.2192382812\n",
      "===> Epoch[2](120/462): Loss: 1220.8542480469\n",
      "===> Epoch[2](130/462): Loss: 1772.6599121094\n",
      "===> Epoch[2](140/462): Loss: 1326.4802246094\n",
      "===> Epoch[2](150/462): Loss: 1410.2285156250\n",
      "===> Epoch[2](160/462): Loss: 1287.3937988281\n",
      "===> Epoch[2](170/462): Loss: 1539.1278076172\n",
      "===> Epoch[2](180/462): Loss: 1778.4283447266\n",
      "===> Epoch[2](190/462): Loss: 1170.4805908203\n",
      "===> Epoch[2](200/462): Loss: 628.7460937500\n",
      "===> Epoch[2](210/462): Loss: 1203.3137207031\n",
      "===> Epoch[2](220/462): Loss: 965.8447265625\n",
      "===> Epoch[2](230/462): Loss: 1233.2984619141\n",
      "===> Epoch[2](240/462): Loss: 2567.5437011719\n",
      "===> Epoch[2](250/462): Loss: 1070.9344482422\n",
      "===> Epoch[2](260/462): Loss: 1634.3889160156\n",
      "===> Epoch[2](270/462): Loss: 1170.7219238281\n",
      "===> Epoch[2](280/462): Loss: 793.3763427734\n",
      "===> Epoch[2](290/462): Loss: 1395.1809082031\n",
      "===> Epoch[2](300/462): Loss: 906.5203247070\n",
      "===> Epoch[2](310/462): Loss: 869.4289550781\n",
      "===> Epoch[2](320/462): Loss: 1077.6750488281\n",
      "===> Epoch[2](330/462): Loss: 1109.3189697266\n",
      "===> Epoch[2](340/462): Loss: 1744.9454345703\n",
      "===> Epoch[2](350/462): Loss: 1680.5975341797\n",
      "===> Epoch[2](360/462): Loss: 1025.2209472656\n",
      "===> Epoch[2](370/462): Loss: 1571.3161621094\n",
      "===> Epoch[2](380/462): Loss: 1410.9177246094\n",
      "===> Epoch[2](390/462): Loss: 1504.3284912109\n",
      "===> Epoch[2](400/462): Loss: 1802.3232421875\n",
      "===> Epoch[2](410/462): Loss: 980.0336914062\n",
      "===> Epoch[2](420/462): Loss: 726.3481445312\n",
      "===> Epoch[2](430/462): Loss: 1597.5280761719\n",
      "===> Epoch[2](440/462): Loss: 1710.1044921875\n",
      "===> Epoch[2](450/462): Loss: 1400.9096679688\n",
      "===> Epoch[2](460/462): Loss: 1414.6943359375\n",
      "Checkpoint saved to checkpoint/model_epoch_2.pth\n",
      "Epoch = 3, lr = 0.1\n",
      "===> Epoch[3](10/462): Loss: 969.4920654297\n",
      "===> Epoch[3](20/462): Loss: 2061.3195800781\n",
      "===> Epoch[3](30/462): Loss: 1319.1538085938\n",
      "===> Epoch[3](40/462): Loss: 1033.8437500000\n",
      "===> Epoch[3](50/462): Loss: 1024.3620605469\n",
      "===> Epoch[3](60/462): Loss: 1447.9415283203\n",
      "===> Epoch[3](70/462): Loss: 1240.5861816406\n",
      "===> Epoch[3](80/462): Loss: 1218.4521484375\n",
      "===> Epoch[3](90/462): Loss: 1080.3974609375\n",
      "===> Epoch[3](100/462): Loss: 990.6531372070\n",
      "===> Epoch[3](110/462): Loss: 1419.1916503906\n",
      "===> Epoch[3](120/462): Loss: 1162.6160888672\n",
      "===> Epoch[3](130/462): Loss: 959.2681884766\n",
      "===> Epoch[3](140/462): Loss: 850.9720458984\n",
      "===> Epoch[3](150/462): Loss: 1520.2687988281\n",
      "===> Epoch[3](160/462): Loss: 865.7503051758\n",
      "===> Epoch[3](170/462): Loss: 1086.8864746094\n",
      "===> Epoch[3](180/462): Loss: 944.9184570312\n",
      "===> Epoch[3](190/462): Loss: 1184.8676757812\n",
      "===> Epoch[3](200/462): Loss: 1324.4163818359\n",
      "===> Epoch[3](210/462): Loss: 862.4114990234\n",
      "===> Epoch[3](220/462): Loss: 1493.0673828125\n",
      "===> Epoch[3](230/462): Loss: 1094.7302246094\n",
      "===> Epoch[3](240/462): Loss: 1129.7982177734\n",
      "===> Epoch[3](250/462): Loss: 977.6732788086\n",
      "===> Epoch[3](260/462): Loss: 1443.4052734375\n",
      "===> Epoch[3](270/462): Loss: 2060.2893066406\n",
      "===> Epoch[3](280/462): Loss: 1535.9421386719\n",
      "===> Epoch[3](290/462): Loss: 1061.2601318359\n",
      "===> Epoch[3](300/462): Loss: 692.7460937500\n",
      "===> Epoch[3](310/462): Loss: 1741.8090820312\n",
      "===> Epoch[3](320/462): Loss: 2281.7395019531\n",
      "===> Epoch[3](330/462): Loss: 569.4279785156\n",
      "===> Epoch[3](340/462): Loss: 1901.5352783203\n",
      "===> Epoch[3](350/462): Loss: 1335.4230957031\n",
      "===> Epoch[3](360/462): Loss: 1530.1729736328\n",
      "===> Epoch[3](370/462): Loss: 1587.3681640625\n",
      "===> Epoch[3](380/462): Loss: 667.8495483398\n",
      "===> Epoch[3](390/462): Loss: 963.1829833984\n",
      "===> Epoch[3](400/462): Loss: 1344.1088867188\n",
      "===> Epoch[3](410/462): Loss: 1676.2785644531\n",
      "===> Epoch[3](420/462): Loss: 686.2130126953\n",
      "===> Epoch[3](430/462): Loss: 1336.8748779297\n",
      "===> Epoch[3](440/462): Loss: 1087.7894287109\n",
      "===> Epoch[3](450/462): Loss: 1142.8419189453\n",
      "===> Epoch[3](460/462): Loss: 1293.2983398438\n",
      "Checkpoint saved to checkpoint/model_epoch_3.pth\n",
      "Epoch = 4, lr = 0.1\n",
      "===> Epoch[4](10/462): Loss: 2172.6884765625\n",
      "===> Epoch[4](20/462): Loss: 1351.0834960938\n",
      "===> Epoch[4](30/462): Loss: 997.2194824219\n",
      "===> Epoch[4](40/462): Loss: 1715.7407226562\n",
      "===> Epoch[4](50/462): Loss: 1416.6157226562\n",
      "===> Epoch[4](60/462): Loss: 1684.5268554688\n",
      "===> Epoch[4](70/462): Loss: 2949.9399414062\n",
      "===> Epoch[4](80/462): Loss: 866.2113037109\n",
      "===> Epoch[4](90/462): Loss: 2109.8845214844\n",
      "===> Epoch[4](100/462): Loss: 1891.8221435547\n",
      "===> Epoch[4](110/462): Loss: 1347.8469238281\n",
      "===> Epoch[4](120/462): Loss: 2151.8801269531\n",
      "===> Epoch[4](130/462): Loss: 1350.3145751953\n",
      "===> Epoch[4](140/462): Loss: 929.8099365234\n",
      "===> Epoch[4](150/462): Loss: 1529.8918457031\n",
      "===> Epoch[4](160/462): Loss: 662.4282836914\n",
      "===> Epoch[4](170/462): Loss: 1420.6403808594\n",
      "===> Epoch[4](180/462): Loss: 1188.0129394531\n",
      "===> Epoch[4](190/462): Loss: 579.2002563477\n",
      "===> Epoch[4](200/462): Loss: 927.5094604492\n",
      "===> Epoch[4](210/462): Loss: 756.2540283203\n",
      "===> Epoch[4](220/462): Loss: 740.3681030273\n",
      "===> Epoch[4](230/462): Loss: 1020.5390014648\n",
      "===> Epoch[4](240/462): Loss: 1054.6235351562\n",
      "===> Epoch[4](250/462): Loss: 752.1131591797\n",
      "===> Epoch[4](260/462): Loss: 546.5548706055\n",
      "===> Epoch[4](270/462): Loss: 1005.2465820312\n",
      "===> Epoch[4](280/462): Loss: 1461.2355957031\n",
      "===> Epoch[4](290/462): Loss: 1124.3875732422\n",
      "===> Epoch[4](300/462): Loss: 1400.6767578125\n",
      "===> Epoch[4](310/462): Loss: 1760.9421386719\n",
      "===> Epoch[4](320/462): Loss: 1479.9207763672\n",
      "===> Epoch[4](330/462): Loss: 1029.0805664062\n",
      "===> Epoch[4](340/462): Loss: 1638.2950439453\n",
      "===> Epoch[4](350/462): Loss: 807.9033203125\n",
      "===> Epoch[4](360/462): Loss: 1106.9877929688\n",
      "===> Epoch[4](370/462): Loss: 2061.0598144531\n",
      "===> Epoch[4](380/462): Loss: 924.8529052734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[4](390/462): Loss: 1291.8695068359\n",
      "===> Epoch[4](400/462): Loss: 1062.6291503906\n",
      "===> Epoch[4](410/462): Loss: 1220.3979492188\n",
      "===> Epoch[4](420/462): Loss: 1018.5102539062\n",
      "===> Epoch[4](430/462): Loss: 993.8936767578\n",
      "===> Epoch[4](440/462): Loss: 689.9306640625\n",
      "===> Epoch[4](450/462): Loss: 1357.5982666016\n",
      "===> Epoch[4](460/462): Loss: 1547.5722656250\n",
      "Checkpoint saved to checkpoint/model_epoch_4.pth\n",
      "Epoch = 5, lr = 0.1\n",
      "===> Epoch[5](10/462): Loss: 796.9346923828\n",
      "===> Epoch[5](20/462): Loss: 1856.7875976562\n",
      "===> Epoch[5](30/462): Loss: 1430.0786132812\n",
      "===> Epoch[5](40/462): Loss: 1565.1282958984\n",
      "===> Epoch[5](50/462): Loss: 1074.0983886719\n",
      "===> Epoch[5](60/462): Loss: 1573.1795654297\n",
      "===> Epoch[5](70/462): Loss: 1021.5621337891\n",
      "===> Epoch[5](80/462): Loss: 962.2158203125\n",
      "===> Epoch[5](90/462): Loss: 937.5678100586\n",
      "===> Epoch[5](100/462): Loss: 1196.1110839844\n",
      "===> Epoch[5](110/462): Loss: 747.2858886719\n",
      "===> Epoch[5](120/462): Loss: 916.1271972656\n",
      "===> Epoch[5](130/462): Loss: 1809.2308349609\n",
      "===> Epoch[5](140/462): Loss: 1432.9047851562\n",
      "===> Epoch[5](150/462): Loss: 968.7997436523\n",
      "===> Epoch[5](160/462): Loss: 1354.8840332031\n",
      "===> Epoch[5](170/462): Loss: 885.3565063477\n",
      "===> Epoch[5](180/462): Loss: 1852.4223632812\n",
      "===> Epoch[5](190/462): Loss: 972.6962890625\n",
      "===> Epoch[5](200/462): Loss: 1170.1085205078\n",
      "===> Epoch[5](210/462): Loss: 1313.5043945312\n",
      "===> Epoch[5](220/462): Loss: 1992.6396484375\n",
      "===> Epoch[5](230/462): Loss: 1128.0550537109\n",
      "===> Epoch[5](240/462): Loss: 1050.0935058594\n",
      "===> Epoch[5](250/462): Loss: 1186.3652343750\n",
      "===> Epoch[5](260/462): Loss: 2272.0244140625\n",
      "===> Epoch[5](270/462): Loss: 746.0911254883\n",
      "===> Epoch[5](280/462): Loss: 1302.9973144531\n",
      "===> Epoch[5](290/462): Loss: 1456.2283935547\n",
      "===> Epoch[5](300/462): Loss: 921.2294311523\n",
      "===> Epoch[5](310/462): Loss: 520.2636108398\n",
      "===> Epoch[5](320/462): Loss: 1525.7446289062\n",
      "===> Epoch[5](330/462): Loss: 1538.6673583984\n",
      "===> Epoch[5](340/462): Loss: 1205.6289062500\n",
      "===> Epoch[5](350/462): Loss: 1469.1651611328\n",
      "===> Epoch[5](360/462): Loss: 952.9925537109\n",
      "===> Epoch[5](370/462): Loss: 1000.3543090820\n",
      "===> Epoch[5](380/462): Loss: 1594.8012695312\n",
      "===> Epoch[5](390/462): Loss: 2193.5341796875\n",
      "===> Epoch[5](400/462): Loss: 1374.0659179688\n",
      "===> Epoch[5](410/462): Loss: 911.2482910156\n",
      "===> Epoch[5](420/462): Loss: 962.9907226562\n",
      "===> Epoch[5](430/462): Loss: 1146.1809082031\n",
      "===> Epoch[5](440/462): Loss: 1105.4367675781\n",
      "===> Epoch[5](450/462): Loss: 1153.9085693359\n",
      "===> Epoch[5](460/462): Loss: 792.1628417969\n",
      "Checkpoint saved to checkpoint/model_epoch_5.pth\n",
      "Epoch = 6, lr = 0.010000000000000002\n",
      "===> Epoch[6](10/462): Loss: 1685.4449462891\n",
      "===> Epoch[6](20/462): Loss: 981.5440673828\n",
      "===> Epoch[6](30/462): Loss: 1133.8395996094\n",
      "===> Epoch[6](40/462): Loss: 1002.0112304688\n",
      "===> Epoch[6](50/462): Loss: 1496.0480957031\n",
      "===> Epoch[6](60/462): Loss: 936.4990844727\n",
      "===> Epoch[6](70/462): Loss: 1433.9772949219\n",
      "===> Epoch[6](80/462): Loss: 1315.1130371094\n",
      "===> Epoch[6](90/462): Loss: 1463.2404785156\n",
      "===> Epoch[6](100/462): Loss: 1166.9909667969\n",
      "===> Epoch[6](110/462): Loss: 1139.6784667969\n",
      "===> Epoch[6](120/462): Loss: 1634.3068847656\n",
      "===> Epoch[6](130/462): Loss: 790.4404907227\n",
      "===> Epoch[6](140/462): Loss: 840.1979370117\n",
      "===> Epoch[6](150/462): Loss: 725.6994018555\n",
      "===> Epoch[6](160/462): Loss: 1030.4197998047\n",
      "===> Epoch[6](170/462): Loss: 1383.2744140625\n",
      "===> Epoch[6](180/462): Loss: 1436.8690185547\n",
      "===> Epoch[6](190/462): Loss: 1521.8435058594\n",
      "===> Epoch[6](200/462): Loss: 1449.3186035156\n",
      "===> Epoch[6](210/462): Loss: 522.4479980469\n",
      "===> Epoch[6](220/462): Loss: 860.3161621094\n",
      "===> Epoch[6](230/462): Loss: 1192.0274658203\n",
      "===> Epoch[6](240/462): Loss: 1354.5258789062\n",
      "===> Epoch[6](250/462): Loss: 1345.9047851562\n",
      "===> Epoch[6](260/462): Loss: 1063.3139648438\n",
      "===> Epoch[6](270/462): Loss: 1191.5642089844\n",
      "===> Epoch[6](280/462): Loss: 1797.7658691406\n",
      "===> Epoch[6](290/462): Loss: 1203.4746093750\n",
      "===> Epoch[6](300/462): Loss: 1523.4155273438\n",
      "===> Epoch[6](310/462): Loss: 1182.5446777344\n",
      "===> Epoch[6](320/462): Loss: 1029.5749511719\n",
      "===> Epoch[6](330/462): Loss: 1278.8049316406\n",
      "===> Epoch[6](340/462): Loss: 1348.4123535156\n",
      "===> Epoch[6](350/462): Loss: 1046.2365722656\n",
      "===> Epoch[6](360/462): Loss: 1130.7135009766\n",
      "===> Epoch[6](370/462): Loss: 768.4716796875\n",
      "===> Epoch[6](380/462): Loss: 1066.1159667969\n",
      "===> Epoch[6](390/462): Loss: 1658.4355468750\n",
      "===> Epoch[6](400/462): Loss: 1093.2968750000\n",
      "===> Epoch[6](410/462): Loss: 1241.3227539062\n",
      "===> Epoch[6](420/462): Loss: 1028.3813476562\n",
      "===> Epoch[6](430/462): Loss: 872.3552246094\n",
      "===> Epoch[6](440/462): Loss: 675.0281982422\n",
      "===> Epoch[6](450/462): Loss: 1627.5019531250\n",
      "===> Epoch[6](460/462): Loss: 1842.8732910156\n",
      "Checkpoint saved to checkpoint/model_epoch_6.pth\n",
      "Epoch = 7, lr = 0.010000000000000002\n",
      "===> Epoch[7](10/462): Loss: 1500.6010742188\n",
      "===> Epoch[7](20/462): Loss: 1036.3845214844\n",
      "===> Epoch[7](30/462): Loss: 1103.8153076172\n",
      "===> Epoch[7](40/462): Loss: 785.4770507812\n",
      "===> Epoch[7](50/462): Loss: 1147.2148437500\n",
      "===> Epoch[7](60/462): Loss: 1253.4733886719\n",
      "===> Epoch[7](70/462): Loss: 969.0203857422\n",
      "===> Epoch[7](80/462): Loss: 685.8396606445\n",
      "===> Epoch[7](90/462): Loss: 885.8198242188\n",
      "===> Epoch[7](100/462): Loss: 675.0427246094\n",
      "===> Epoch[7](110/462): Loss: 1526.5634765625\n",
      "===> Epoch[7](120/462): Loss: 1403.8781738281\n",
      "===> Epoch[7](130/462): Loss: 1157.2758789062\n",
      "===> Epoch[7](140/462): Loss: 812.2419433594\n",
      "===> Epoch[7](150/462): Loss: 1984.4034423828\n",
      "===> Epoch[7](160/462): Loss: 1975.0625000000\n",
      "===> Epoch[7](170/462): Loss: 1073.8364257812\n",
      "===> Epoch[7](180/462): Loss: 830.1477050781\n",
      "===> Epoch[7](190/462): Loss: 956.7250366211\n",
      "===> Epoch[7](200/462): Loss: 1271.1101074219\n",
      "===> Epoch[7](210/462): Loss: 674.8112792969\n",
      "===> Epoch[7](220/462): Loss: 817.9473876953\n",
      "===> Epoch[7](230/462): Loss: 2524.9077148438\n",
      "===> Epoch[7](240/462): Loss: 1350.7493896484\n",
      "===> Epoch[7](250/462): Loss: 1276.5275878906\n",
      "===> Epoch[7](260/462): Loss: 1054.4323730469\n",
      "===> Epoch[7](270/462): Loss: 902.8768920898\n",
      "===> Epoch[7](280/462): Loss: 1264.7207031250\n",
      "===> Epoch[7](290/462): Loss: 1731.1486816406\n",
      "===> Epoch[7](300/462): Loss: 1530.0019531250\n",
      "===> Epoch[7](310/462): Loss: 1316.7653808594\n",
      "===> Epoch[7](320/462): Loss: 1774.7878417969\n",
      "===> Epoch[7](330/462): Loss: 1271.7307128906\n",
      "===> Epoch[7](340/462): Loss: 1625.0236816406\n",
      "===> Epoch[7](350/462): Loss: 1430.2341308594\n",
      "===> Epoch[7](360/462): Loss: 1243.9206542969\n",
      "===> Epoch[7](370/462): Loss: 1168.0708007812\n",
      "===> Epoch[7](380/462): Loss: 786.1220703125\n",
      "===> Epoch[7](390/462): Loss: 1304.1191406250\n",
      "===> Epoch[7](400/462): Loss: 1041.6177978516\n",
      "===> Epoch[7](410/462): Loss: 1170.8261718750\n",
      "===> Epoch[7](420/462): Loss: 709.1074218750\n",
      "===> Epoch[7](430/462): Loss: 911.1315917969\n",
      "===> Epoch[7](440/462): Loss: 1692.8090820312\n",
      "===> Epoch[7](450/462): Loss: 947.7089843750\n",
      "===> Epoch[7](460/462): Loss: 943.9992675781\n",
      "Checkpoint saved to checkpoint/model_epoch_7.pth\n",
      "Epoch = 8, lr = 0.010000000000000002\n",
      "===> Epoch[8](10/462): Loss: 956.0546875000\n",
      "===> Epoch[8](20/462): Loss: 1240.5960693359\n",
      "===> Epoch[8](30/462): Loss: 1101.8093261719\n",
      "===> Epoch[8](40/462): Loss: 1605.9841308594\n",
      "===> Epoch[8](50/462): Loss: 981.8856811523\n",
      "===> Epoch[8](60/462): Loss: 1695.2856445312\n",
      "===> Epoch[8](70/462): Loss: 1886.5898437500\n",
      "===> Epoch[8](80/462): Loss: 847.5627441406\n",
      "===> Epoch[8](90/462): Loss: 1244.1279296875\n",
      "===> Epoch[8](100/462): Loss: 1490.5295410156\n",
      "===> Epoch[8](110/462): Loss: 1251.6794433594\n",
      "===> Epoch[8](120/462): Loss: 1064.4343261719\n",
      "===> Epoch[8](130/462): Loss: 794.5603027344\n",
      "===> Epoch[8](140/462): Loss: 1488.0800781250\n",
      "===> Epoch[8](150/462): Loss: 845.5343627930\n",
      "===> Epoch[8](160/462): Loss: 1351.7562255859\n",
      "===> Epoch[8](170/462): Loss: 1896.7894287109\n",
      "===> Epoch[8](180/462): Loss: 1609.5886230469\n",
      "===> Epoch[8](190/462): Loss: 618.9869995117\n",
      "===> Epoch[8](200/462): Loss: 1382.1633300781\n",
      "===> Epoch[8](210/462): Loss: 979.9382324219\n",
      "===> Epoch[8](220/462): Loss: 1028.5543212891\n",
      "===> Epoch[8](230/462): Loss: 966.6018066406\n",
      "===> Epoch[8](240/462): Loss: 1018.6232910156\n",
      "===> Epoch[8](250/462): Loss: 1360.6196289062\n",
      "===> Epoch[8](260/462): Loss: 1261.7517089844\n",
      "===> Epoch[8](270/462): Loss: 810.5524902344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[8](280/462): Loss: 1455.4941406250\n",
      "===> Epoch[8](290/462): Loss: 1929.8295898438\n",
      "===> Epoch[8](300/462): Loss: 1075.2585449219\n",
      "===> Epoch[8](310/462): Loss: 1024.4141845703\n",
      "===> Epoch[8](320/462): Loss: 1283.0803222656\n",
      "===> Epoch[8](330/462): Loss: 1183.7980957031\n",
      "===> Epoch[8](340/462): Loss: 950.0357666016\n",
      "===> Epoch[8](350/462): Loss: 784.3314208984\n",
      "===> Epoch[8](360/462): Loss: 1040.4631347656\n",
      "===> Epoch[8](370/462): Loss: 1343.9645996094\n",
      "===> Epoch[8](380/462): Loss: 1081.0681152344\n",
      "===> Epoch[8](390/462): Loss: 932.1453857422\n",
      "===> Epoch[8](400/462): Loss: 992.7127685547\n",
      "===> Epoch[8](410/462): Loss: 1325.1328125000\n",
      "===> Epoch[8](420/462): Loss: 1095.1545410156\n",
      "===> Epoch[8](430/462): Loss: 873.1282958984\n",
      "===> Epoch[8](440/462): Loss: 849.8325195312\n",
      "===> Epoch[8](450/462): Loss: 1305.6027832031\n",
      "===> Epoch[8](460/462): Loss: 881.7731933594\n",
      "Checkpoint saved to checkpoint/model_epoch_8.pth\n",
      "Epoch = 9, lr = 0.010000000000000002\n",
      "===> Epoch[9](10/462): Loss: 1008.2532958984\n",
      "===> Epoch[9](20/462): Loss: 1412.4630126953\n",
      "===> Epoch[9](30/462): Loss: 1031.4609375000\n",
      "===> Epoch[9](40/462): Loss: 1555.4638671875\n",
      "===> Epoch[9](50/462): Loss: 1289.7205810547\n",
      "===> Epoch[9](60/462): Loss: 1696.2427978516\n",
      "===> Epoch[9](70/462): Loss: 616.5698242188\n",
      "===> Epoch[9](80/462): Loss: 893.1452636719\n",
      "===> Epoch[9](90/462): Loss: 1330.8088378906\n",
      "===> Epoch[9](100/462): Loss: 539.0933837891\n",
      "===> Epoch[9](110/462): Loss: 705.1612548828\n",
      "===> Epoch[9](120/462): Loss: 1460.9581298828\n",
      "===> Epoch[9](130/462): Loss: 996.9256591797\n",
      "===> Epoch[9](140/462): Loss: 1617.6680908203\n",
      "===> Epoch[9](150/462): Loss: 2228.5356445312\n",
      "===> Epoch[9](160/462): Loss: 1391.9831542969\n",
      "===> Epoch[9](170/462): Loss: 864.5377807617\n",
      "===> Epoch[9](180/462): Loss: 1019.9541015625\n",
      "===> Epoch[9](190/462): Loss: 1131.7801513672\n",
      "===> Epoch[9](200/462): Loss: 1275.4090576172\n",
      "===> Epoch[9](210/462): Loss: 1720.5795898438\n",
      "===> Epoch[9](220/462): Loss: 1237.2536621094\n",
      "===> Epoch[9](230/462): Loss: 773.7864990234\n",
      "===> Epoch[9](240/462): Loss: 611.5592041016\n",
      "===> Epoch[9](250/462): Loss: 1175.8979492188\n",
      "===> Epoch[9](260/462): Loss: 892.3183593750\n",
      "===> Epoch[9](270/462): Loss: 1269.0924072266\n",
      "===> Epoch[9](280/462): Loss: 1104.4423828125\n",
      "===> Epoch[9](290/462): Loss: 581.7315673828\n",
      "===> Epoch[9](300/462): Loss: 622.4238891602\n",
      "===> Epoch[9](310/462): Loss: 1045.6115722656\n",
      "===> Epoch[9](320/462): Loss: 1124.0776367188\n",
      "===> Epoch[9](330/462): Loss: 892.2274169922\n",
      "===> Epoch[9](340/462): Loss: 1767.8665771484\n",
      "===> Epoch[9](350/462): Loss: 1264.3947753906\n",
      "===> Epoch[9](360/462): Loss: 1074.3793945312\n",
      "===> Epoch[9](370/462): Loss: 3363.0307617188\n",
      "===> Epoch[9](380/462): Loss: 1023.1510620117\n",
      "===> Epoch[9](390/462): Loss: 917.2722167969\n",
      "===> Epoch[9](400/462): Loss: 1546.9907226562\n",
      "===> Epoch[9](410/462): Loss: 1194.6260986328\n",
      "===> Epoch[9](420/462): Loss: 907.7305297852\n",
      "===> Epoch[9](430/462): Loss: 1184.2882080078\n",
      "===> Epoch[9](440/462): Loss: 1934.7863769531\n",
      "===> Epoch[9](450/462): Loss: 1180.7615966797\n",
      "===> Epoch[9](460/462): Loss: 1443.7104492188\n",
      "Checkpoint saved to checkpoint/model_epoch_9.pth\n",
      "Epoch = 10, lr = 0.010000000000000002\n",
      "===> Epoch[10](10/462): Loss: 850.3520507812\n",
      "===> Epoch[10](20/462): Loss: 1119.8317871094\n",
      "===> Epoch[10](30/462): Loss: 1166.4925537109\n",
      "===> Epoch[10](40/462): Loss: 1222.3981933594\n",
      "===> Epoch[10](50/462): Loss: 1733.1468505859\n",
      "===> Epoch[10](60/462): Loss: 823.2175292969\n",
      "===> Epoch[10](70/462): Loss: 1281.6079101562\n",
      "===> Epoch[10](80/462): Loss: 1521.5527343750\n",
      "===> Epoch[10](90/462): Loss: 943.1329345703\n",
      "===> Epoch[10](100/462): Loss: 1283.5892333984\n",
      "===> Epoch[10](110/462): Loss: 833.6859741211\n",
      "===> Epoch[10](120/462): Loss: 1779.6660156250\n",
      "===> Epoch[10](130/462): Loss: 853.6511840820\n",
      "===> Epoch[10](140/462): Loss: 784.5190429688\n",
      "===> Epoch[10](150/462): Loss: 2054.0180664062\n",
      "===> Epoch[10](160/462): Loss: 1060.3454589844\n",
      "===> Epoch[10](170/462): Loss: 876.4285888672\n",
      "===> Epoch[10](180/462): Loss: 854.3849487305\n",
      "===> Epoch[10](190/462): Loss: 1165.4304199219\n",
      "===> Epoch[10](200/462): Loss: 1965.1901855469\n",
      "===> Epoch[10](210/462): Loss: 2116.6088867188\n",
      "===> Epoch[10](220/462): Loss: 1005.6808471680\n",
      "===> Epoch[10](230/462): Loss: 1032.9750976562\n",
      "===> Epoch[10](240/462): Loss: 1194.9851074219\n",
      "===> Epoch[10](250/462): Loss: 1062.3099365234\n",
      "===> Epoch[10](260/462): Loss: 903.0985107422\n",
      "===> Epoch[10](270/462): Loss: 1139.8259277344\n",
      "===> Epoch[10](280/462): Loss: 1021.3587036133\n",
      "===> Epoch[10](290/462): Loss: 1107.1098632812\n",
      "===> Epoch[10](300/462): Loss: 1828.0585937500\n",
      "===> Epoch[10](310/462): Loss: 918.3238525391\n",
      "===> Epoch[10](320/462): Loss: 1565.5869140625\n",
      "===> Epoch[10](330/462): Loss: 1320.8957519531\n",
      "===> Epoch[10](340/462): Loss: 555.1173095703\n",
      "===> Epoch[10](350/462): Loss: 948.5294189453\n",
      "===> Epoch[10](360/462): Loss: 1067.0169677734\n",
      "===> Epoch[10](370/462): Loss: 1040.8564453125\n",
      "===> Epoch[10](380/462): Loss: 1451.8609619141\n",
      "===> Epoch[10](390/462): Loss: 1366.3715820312\n",
      "===> Epoch[10](400/462): Loss: 1737.2729492188\n",
      "===> Epoch[10](410/462): Loss: 938.1029052734\n",
      "===> Epoch[10](420/462): Loss: 1126.1658935547\n",
      "===> Epoch[10](430/462): Loss: 1902.7219238281\n",
      "===> Epoch[10](440/462): Loss: 984.6529541016\n",
      "===> Epoch[10](450/462): Loss: 1467.2431640625\n",
      "===> Epoch[10](460/462): Loss: 1181.2893066406\n",
      "Checkpoint saved to checkpoint/model_epoch_10.pth\n",
      "Epoch = 11, lr = 0.0010000000000000002\n",
      "===> Epoch[11](10/462): Loss: 1521.8806152344\n",
      "===> Epoch[11](20/462): Loss: 922.5040283203\n",
      "===> Epoch[11](30/462): Loss: 1017.0650634766\n",
      "===> Epoch[11](40/462): Loss: 991.3247680664\n",
      "===> Epoch[11](50/462): Loss: 1072.1419677734\n",
      "===> Epoch[11](60/462): Loss: 1333.3039550781\n",
      "===> Epoch[11](70/462): Loss: 866.7025146484\n",
      "===> Epoch[11](80/462): Loss: 1155.1870117188\n",
      "===> Epoch[11](90/462): Loss: 1272.8452148438\n",
      "===> Epoch[11](100/462): Loss: 1151.8391113281\n",
      "===> Epoch[11](110/462): Loss: 462.2497253418\n",
      "===> Epoch[11](120/462): Loss: 1588.8405761719\n",
      "===> Epoch[11](130/462): Loss: 1626.5682373047\n",
      "===> Epoch[11](140/462): Loss: 1336.2072753906\n",
      "===> Epoch[11](150/462): Loss: 1491.2056884766\n",
      "===> Epoch[11](160/462): Loss: 1390.3720703125\n",
      "===> Epoch[11](170/462): Loss: 1043.6311035156\n",
      "===> Epoch[11](180/462): Loss: 1274.2126464844\n",
      "===> Epoch[11](190/462): Loss: 1193.3342285156\n",
      "===> Epoch[11](200/462): Loss: 1074.3923339844\n",
      "===> Epoch[11](210/462): Loss: 1227.5434570312\n",
      "===> Epoch[11](220/462): Loss: 902.8520507812\n",
      "===> Epoch[11](230/462): Loss: 864.1577148438\n",
      "===> Epoch[11](240/462): Loss: 1299.8643798828\n",
      "===> Epoch[11](250/462): Loss: 1174.5484619141\n",
      "===> Epoch[11](260/462): Loss: 1554.7253417969\n",
      "===> Epoch[11](270/462): Loss: 1003.8251342773\n",
      "===> Epoch[11](280/462): Loss: 1892.0959472656\n",
      "===> Epoch[11](290/462): Loss: 1537.2459716797\n",
      "===> Epoch[11](300/462): Loss: 1566.4338378906\n",
      "===> Epoch[11](310/462): Loss: 1124.0256347656\n",
      "===> Epoch[11](320/462): Loss: 1046.4006347656\n",
      "===> Epoch[11](330/462): Loss: 1536.3884277344\n",
      "===> Epoch[11](340/462): Loss: 1096.5173339844\n",
      "===> Epoch[11](350/462): Loss: 1069.3461914062\n",
      "===> Epoch[11](360/462): Loss: 849.9650878906\n",
      "===> Epoch[11](370/462): Loss: 794.3708496094\n",
      "===> Epoch[11](380/462): Loss: 945.2531738281\n",
      "===> Epoch[11](390/462): Loss: 1052.1291503906\n",
      "===> Epoch[11](400/462): Loss: 1297.7601318359\n",
      "===> Epoch[11](410/462): Loss: 1625.3381347656\n",
      "===> Epoch[11](420/462): Loss: 1931.9577636719\n",
      "===> Epoch[11](430/462): Loss: 924.7262573242\n",
      "===> Epoch[11](440/462): Loss: 1254.2731933594\n",
      "===> Epoch[11](450/462): Loss: 1957.0987548828\n",
      "===> Epoch[11](460/462): Loss: 995.4931640625\n",
      "Checkpoint saved to checkpoint/model_epoch_11.pth\n",
      "Epoch = 12, lr = 0.0010000000000000002\n",
      "===> Epoch[12](10/462): Loss: 839.2700195312\n",
      "===> Epoch[12](20/462): Loss: 1041.1273193359\n",
      "===> Epoch[12](30/462): Loss: 1154.9348144531\n",
      "===> Epoch[12](40/462): Loss: 1188.3961181641\n",
      "===> Epoch[12](50/462): Loss: 1544.9499511719\n",
      "===> Epoch[12](60/462): Loss: 1068.5808105469\n",
      "===> Epoch[12](70/462): Loss: 1040.3566894531\n",
      "===> Epoch[12](80/462): Loss: 1193.4057617188\n",
      "===> Epoch[12](90/462): Loss: 1967.5529785156\n",
      "===> Epoch[12](100/462): Loss: 1268.4665527344\n",
      "===> Epoch[12](110/462): Loss: 923.7666625977\n",
      "===> Epoch[12](120/462): Loss: 1233.7745361328\n",
      "===> Epoch[12](130/462): Loss: 1135.7611083984\n",
      "===> Epoch[12](140/462): Loss: 1287.2973632812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[12](150/462): Loss: 1046.8128662109\n",
      "===> Epoch[12](160/462): Loss: 1050.8325195312\n",
      "===> Epoch[12](170/462): Loss: 1324.5930175781\n",
      "===> Epoch[12](180/462): Loss: 1219.5600585938\n",
      "===> Epoch[12](190/462): Loss: 1323.1435546875\n",
      "===> Epoch[12](200/462): Loss: 952.6604614258\n",
      "===> Epoch[12](210/462): Loss: 807.1750488281\n",
      "===> Epoch[12](220/462): Loss: 1543.2919921875\n",
      "===> Epoch[12](230/462): Loss: 1285.3745117188\n",
      "===> Epoch[12](240/462): Loss: 1066.1480712891\n",
      "===> Epoch[12](250/462): Loss: 1536.1228027344\n",
      "===> Epoch[12](260/462): Loss: 880.3024902344\n",
      "===> Epoch[12](270/462): Loss: 729.1774902344\n",
      "===> Epoch[12](280/462): Loss: 1476.2973632812\n",
      "===> Epoch[12](290/462): Loss: 845.4057006836\n",
      "===> Epoch[12](300/462): Loss: 1069.2635498047\n",
      "===> Epoch[12](310/462): Loss: 591.9670410156\n",
      "===> Epoch[12](320/462): Loss: 2100.3774414062\n",
      "===> Epoch[12](330/462): Loss: 582.0338134766\n",
      "===> Epoch[12](340/462): Loss: 847.1041259766\n",
      "===> Epoch[12](350/462): Loss: 1111.8017578125\n",
      "===> Epoch[12](360/462): Loss: 1320.2613525391\n",
      "===> Epoch[12](370/462): Loss: 1361.0955810547\n",
      "===> Epoch[12](380/462): Loss: 1652.5307617188\n",
      "===> Epoch[12](390/462): Loss: 1329.2197265625\n",
      "===> Epoch[12](400/462): Loss: 1546.5810546875\n",
      "===> Epoch[12](410/462): Loss: 808.8098754883\n",
      "===> Epoch[12](420/462): Loss: 1909.7229003906\n",
      "===> Epoch[12](430/462): Loss: 1160.2658691406\n",
      "===> Epoch[12](440/462): Loss: 1211.6943359375\n",
      "===> Epoch[12](450/462): Loss: 1103.7839355469\n",
      "===> Epoch[12](460/462): Loss: 1825.3000488281\n",
      "Checkpoint saved to checkpoint/model_epoch_12.pth\n",
      "Epoch = 13, lr = 0.0010000000000000002\n",
      "===> Epoch[13](10/462): Loss: 1225.7080078125\n",
      "===> Epoch[13](20/462): Loss: 902.9265747070\n",
      "===> Epoch[13](30/462): Loss: 1083.7956542969\n",
      "===> Epoch[13](40/462): Loss: 1322.6359863281\n",
      "===> Epoch[13](50/462): Loss: 1235.6121826172\n",
      "===> Epoch[13](60/462): Loss: 957.3598632812\n",
      "===> Epoch[13](70/462): Loss: 1260.7492675781\n",
      "===> Epoch[13](80/462): Loss: 1041.2973632812\n",
      "===> Epoch[13](90/462): Loss: 1090.7413330078\n",
      "===> Epoch[13](100/462): Loss: 1806.0198974609\n",
      "===> Epoch[13](110/462): Loss: 1550.8132324219\n",
      "===> Epoch[13](120/462): Loss: 727.9607543945\n",
      "===> Epoch[13](130/462): Loss: 1995.1643066406\n",
      "===> Epoch[13](140/462): Loss: 675.3929443359\n",
      "===> Epoch[13](150/462): Loss: 1044.8837890625\n",
      "===> Epoch[13](160/462): Loss: 970.3136596680\n",
      "===> Epoch[13](170/462): Loss: 1364.3967285156\n",
      "===> Epoch[13](180/462): Loss: 1386.1076660156\n",
      "===> Epoch[13](190/462): Loss: 968.1580810547\n",
      "===> Epoch[13](200/462): Loss: 2164.9086914062\n",
      "===> Epoch[13](210/462): Loss: 1858.6452636719\n",
      "===> Epoch[13](220/462): Loss: 1227.8128662109\n",
      "===> Epoch[13](230/462): Loss: 938.3630371094\n",
      "===> Epoch[13](240/462): Loss: 1567.4584960938\n",
      "===> Epoch[13](250/462): Loss: 1312.5550537109\n",
      "===> Epoch[13](260/462): Loss: 1356.4729003906\n",
      "===> Epoch[13](270/462): Loss: 920.6822509766\n",
      "===> Epoch[13](280/462): Loss: 1583.4023437500\n",
      "===> Epoch[13](290/462): Loss: 1303.5214843750\n",
      "===> Epoch[13](300/462): Loss: 1248.0932617188\n",
      "===> Epoch[13](310/462): Loss: 995.2249755859\n",
      "===> Epoch[13](320/462): Loss: 1303.7496337891\n",
      "===> Epoch[13](330/462): Loss: 2062.7778320312\n",
      "===> Epoch[13](340/462): Loss: 1060.3068847656\n",
      "===> Epoch[13](350/462): Loss: 1724.3500976562\n",
      "===> Epoch[13](360/462): Loss: 959.7805175781\n",
      "===> Epoch[13](370/462): Loss: 1087.2399902344\n",
      "===> Epoch[13](380/462): Loss: 1110.8879394531\n",
      "===> Epoch[13](390/462): Loss: 1264.4365234375\n",
      "===> Epoch[13](400/462): Loss: 926.8359375000\n",
      "===> Epoch[13](410/462): Loss: 1252.6550292969\n",
      "===> Epoch[13](420/462): Loss: 886.7150878906\n",
      "===> Epoch[13](430/462): Loss: 1233.4246826172\n",
      "===> Epoch[13](440/462): Loss: 1295.5888671875\n",
      "===> Epoch[13](450/462): Loss: 1294.7275390625\n",
      "===> Epoch[13](460/462): Loss: 1125.0993652344\n",
      "Checkpoint saved to checkpoint/model_epoch_13.pth\n",
      "Epoch = 14, lr = 0.0010000000000000002\n",
      "===> Epoch[14](10/462): Loss: 1138.3996582031\n",
      "===> Epoch[14](20/462): Loss: 646.4046630859\n",
      "===> Epoch[14](30/462): Loss: 1857.7884521484\n",
      "===> Epoch[14](40/462): Loss: 959.7080688477\n",
      "===> Epoch[14](50/462): Loss: 1018.6497802734\n",
      "===> Epoch[14](60/462): Loss: 1009.6330566406\n",
      "===> Epoch[14](70/462): Loss: 2252.0014648438\n",
      "===> Epoch[14](80/462): Loss: 1317.2436523438\n",
      "===> Epoch[14](90/462): Loss: 928.3792724609\n",
      "===> Epoch[14](100/462): Loss: 1366.2270507812\n",
      "===> Epoch[14](110/462): Loss: 1167.3581542969\n",
      "===> Epoch[14](120/462): Loss: 1453.1072998047\n",
      "===> Epoch[14](130/462): Loss: 1324.0710449219\n",
      "===> Epoch[14](140/462): Loss: 2041.5029296875\n",
      "===> Epoch[14](150/462): Loss: 706.3143920898\n",
      "===> Epoch[14](160/462): Loss: 1489.2183837891\n",
      "===> Epoch[14](170/462): Loss: 1395.2020263672\n",
      "===> Epoch[14](180/462): Loss: 1527.9824218750\n",
      "===> Epoch[14](190/462): Loss: 840.2836914062\n",
      "===> Epoch[14](200/462): Loss: 1716.3425292969\n",
      "===> Epoch[14](210/462): Loss: 1111.5125732422\n",
      "===> Epoch[14](220/462): Loss: 912.8018798828\n",
      "===> Epoch[14](230/462): Loss: 1026.9365234375\n",
      "===> Epoch[14](240/462): Loss: 659.8011474609\n",
      "===> Epoch[14](250/462): Loss: 1811.0793457031\n",
      "===> Epoch[14](260/462): Loss: 1273.5136718750\n",
      "===> Epoch[14](270/462): Loss: 1356.7360839844\n",
      "===> Epoch[14](280/462): Loss: 2050.0927734375\n",
      "===> Epoch[14](290/462): Loss: 964.6711425781\n",
      "===> Epoch[14](300/462): Loss: 1050.5247802734\n",
      "===> Epoch[14](310/462): Loss: 972.3087158203\n",
      "===> Epoch[14](320/462): Loss: 617.2042236328\n",
      "===> Epoch[14](330/462): Loss: 1016.2241210938\n",
      "===> Epoch[14](340/462): Loss: 1896.8851318359\n",
      "===> Epoch[14](350/462): Loss: 2923.6140136719\n",
      "===> Epoch[14](360/462): Loss: 1496.2597656250\n",
      "===> Epoch[14](370/462): Loss: 1450.5369873047\n",
      "===> Epoch[14](380/462): Loss: 2151.7624511719\n",
      "===> Epoch[14](390/462): Loss: 1402.7447509766\n",
      "===> Epoch[14](400/462): Loss: 1138.2749023438\n",
      "===> Epoch[14](410/462): Loss: 1080.7160644531\n",
      "===> Epoch[14](420/462): Loss: 1493.6098632812\n",
      "===> Epoch[14](430/462): Loss: 1116.2670898438\n",
      "===> Epoch[14](440/462): Loss: 1491.9086914062\n",
      "===> Epoch[14](450/462): Loss: 1018.9373168945\n",
      "===> Epoch[14](460/462): Loss: 902.9316406250\n",
      "Checkpoint saved to checkpoint/model_epoch_14.pth\n",
      "Epoch = 15, lr = 0.0010000000000000002\n",
      "===> Epoch[15](10/462): Loss: 870.7844238281\n",
      "===> Epoch[15](20/462): Loss: 1373.1054687500\n",
      "===> Epoch[15](30/462): Loss: 945.2026977539\n",
      "===> Epoch[15](40/462): Loss: 1495.6503906250\n",
      "===> Epoch[15](50/462): Loss: 653.2271118164\n",
      "===> Epoch[15](60/462): Loss: 944.7739868164\n",
      "===> Epoch[15](70/462): Loss: 890.0119628906\n",
      "===> Epoch[15](80/462): Loss: 1391.0759277344\n",
      "===> Epoch[15](90/462): Loss: 1217.9978027344\n",
      "===> Epoch[15](100/462): Loss: 1203.4929199219\n",
      "===> Epoch[15](110/462): Loss: 1188.2724609375\n",
      "===> Epoch[15](120/462): Loss: 808.9630126953\n",
      "===> Epoch[15](130/462): Loss: 719.1052246094\n",
      "===> Epoch[15](140/462): Loss: 1002.6920776367\n",
      "===> Epoch[15](150/462): Loss: 1130.2031250000\n",
      "===> Epoch[15](160/462): Loss: 593.6990356445\n",
      "===> Epoch[15](170/462): Loss: 1526.8009033203\n",
      "===> Epoch[15](180/462): Loss: 2079.6337890625\n",
      "===> Epoch[15](190/462): Loss: 1583.6457519531\n",
      "===> Epoch[15](200/462): Loss: 1006.6728515625\n",
      "===> Epoch[15](210/462): Loss: 1940.8801269531\n",
      "===> Epoch[15](220/462): Loss: 958.6414794922\n",
      "===> Epoch[15](230/462): Loss: 1177.1979980469\n",
      "===> Epoch[15](240/462): Loss: 1320.1433105469\n",
      "===> Epoch[15](250/462): Loss: 953.9818115234\n",
      "===> Epoch[15](260/462): Loss: 1762.2650146484\n",
      "===> Epoch[15](270/462): Loss: 869.4868164062\n",
      "===> Epoch[15](280/462): Loss: 1004.2164306641\n",
      "===> Epoch[15](290/462): Loss: 2350.6977539062\n",
      "===> Epoch[15](300/462): Loss: 938.1781005859\n",
      "===> Epoch[15](310/462): Loss: 1486.2418212891\n",
      "===> Epoch[15](320/462): Loss: 845.3451538086\n",
      "===> Epoch[15](330/462): Loss: 956.0252075195\n",
      "===> Epoch[15](340/462): Loss: 1480.2558593750\n",
      "===> Epoch[15](350/462): Loss: 1447.5809326172\n",
      "===> Epoch[15](360/462): Loss: 1319.5114746094\n",
      "===> Epoch[15](370/462): Loss: 910.4589233398\n",
      "===> Epoch[15](380/462): Loss: 1084.6074218750\n",
      "===> Epoch[15](390/462): Loss: 560.3760986328\n",
      "===> Epoch[15](400/462): Loss: 1214.1318359375\n",
      "===> Epoch[15](410/462): Loss: 1265.9532470703\n",
      "===> Epoch[15](420/462): Loss: 1283.7446289062\n",
      "===> Epoch[15](430/462): Loss: 1981.8548583984\n",
      "===> Epoch[15](440/462): Loss: 812.3526000977\n",
      "===> Epoch[15](450/462): Loss: 1303.7253417969\n",
      "===> Epoch[15](460/462): Loss: 900.4238281250\n",
      "Checkpoint saved to checkpoint/model_epoch_15.pth\n",
      "Epoch = 16, lr = 0.00010000000000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[16](10/462): Loss: 1153.3150634766\n",
      "===> Epoch[16](20/462): Loss: 1350.1535644531\n",
      "===> Epoch[16](30/462): Loss: 1265.7330322266\n",
      "===> Epoch[16](40/462): Loss: 1784.8914794922\n",
      "===> Epoch[16](50/462): Loss: 998.7589721680\n",
      "===> Epoch[16](60/462): Loss: 1107.1409912109\n",
      "===> Epoch[16](70/462): Loss: 1134.6346435547\n",
      "===> Epoch[16](80/462): Loss: 1194.3013916016\n",
      "===> Epoch[16](90/462): Loss: 911.9483642578\n",
      "===> Epoch[16](100/462): Loss: 1041.9838867188\n",
      "===> Epoch[16](110/462): Loss: 1078.4066162109\n",
      "===> Epoch[16](120/462): Loss: 1366.3137207031\n",
      "===> Epoch[16](130/462): Loss: 1033.8145751953\n",
      "===> Epoch[16](140/462): Loss: 1499.9614257812\n",
      "===> Epoch[16](150/462): Loss: 969.0288696289\n",
      "===> Epoch[16](160/462): Loss: 1448.9743652344\n",
      "===> Epoch[16](170/462): Loss: 586.0979003906\n",
      "===> Epoch[16](180/462): Loss: 690.6323242188\n",
      "===> Epoch[16](190/462): Loss: 890.1898193359\n",
      "===> Epoch[16](200/462): Loss: 759.0410766602\n",
      "===> Epoch[16](210/462): Loss: 684.1329345703\n",
      "===> Epoch[16](220/462): Loss: 1347.8347167969\n",
      "===> Epoch[16](230/462): Loss: 934.1872558594\n",
      "===> Epoch[16](240/462): Loss: 1265.9841308594\n",
      "===> Epoch[16](250/462): Loss: 1556.3411865234\n",
      "===> Epoch[16](260/462): Loss: 2342.7709960938\n",
      "===> Epoch[16](270/462): Loss: 1157.8603515625\n",
      "===> Epoch[16](280/462): Loss: 1804.3405761719\n",
      "===> Epoch[16](290/462): Loss: 1525.8824462891\n",
      "===> Epoch[16](300/462): Loss: 1273.2476806641\n",
      "===> Epoch[16](310/462): Loss: 1104.7780761719\n",
      "===> Epoch[16](320/462): Loss: 1085.6204833984\n",
      "===> Epoch[16](330/462): Loss: 676.7684326172\n",
      "===> Epoch[16](340/462): Loss: 1319.0943603516\n",
      "===> Epoch[16](350/462): Loss: 1056.6170654297\n",
      "===> Epoch[16](360/462): Loss: 1171.7871093750\n",
      "===> Epoch[16](370/462): Loss: 1274.6431884766\n",
      "===> Epoch[16](380/462): Loss: 1011.3288574219\n",
      "===> Epoch[16](390/462): Loss: 1270.2487792969\n",
      "===> Epoch[16](400/462): Loss: 1421.3999023438\n",
      "===> Epoch[16](410/462): Loss: 943.1129150391\n",
      "===> Epoch[16](420/462): Loss: 1334.3763427734\n",
      "===> Epoch[16](430/462): Loss: 1449.1048583984\n",
      "===> Epoch[16](440/462): Loss: 946.7971191406\n",
      "===> Epoch[16](450/462): Loss: 1465.4179687500\n",
      "===> Epoch[16](460/462): Loss: 1271.5156250000\n",
      "Checkpoint saved to checkpoint/model_epoch_16.pth\n",
      "Epoch = 17, lr = 0.00010000000000000003\n",
      "===> Epoch[17](10/462): Loss: 1946.0721435547\n",
      "===> Epoch[17](20/462): Loss: 1464.4746093750\n",
      "===> Epoch[17](30/462): Loss: 1257.7406005859\n",
      "===> Epoch[17](40/462): Loss: 926.3818969727\n",
      "===> Epoch[17](50/462): Loss: 1017.8341064453\n",
      "===> Epoch[17](60/462): Loss: 1302.0760498047\n",
      "===> Epoch[17](70/462): Loss: 1152.4675292969\n",
      "===> Epoch[17](80/462): Loss: 1211.8255615234\n",
      "===> Epoch[17](90/462): Loss: 1460.4843750000\n",
      "===> Epoch[17](100/462): Loss: 822.2108764648\n",
      "===> Epoch[17](110/462): Loss: 868.7916259766\n",
      "===> Epoch[17](120/462): Loss: 1811.2087402344\n",
      "===> Epoch[17](130/462): Loss: 1415.1359863281\n",
      "===> Epoch[17](140/462): Loss: 1413.9296875000\n",
      "===> Epoch[17](150/462): Loss: 1202.6923828125\n",
      "===> Epoch[17](160/462): Loss: 1454.2463378906\n",
      "===> Epoch[17](170/462): Loss: 1277.2188720703\n",
      "===> Epoch[17](180/462): Loss: 1138.6872558594\n",
      "===> Epoch[17](190/462): Loss: 912.7430419922\n",
      "===> Epoch[17](200/462): Loss: 935.1165771484\n",
      "===> Epoch[17](210/462): Loss: 693.6271972656\n",
      "===> Epoch[17](220/462): Loss: 1244.9245605469\n",
      "===> Epoch[17](230/462): Loss: 1910.9130859375\n",
      "===> Epoch[17](240/462): Loss: 886.2831420898\n",
      "===> Epoch[17](250/462): Loss: 1145.6441650391\n",
      "===> Epoch[17](260/462): Loss: 882.1181640625\n",
      "===> Epoch[17](270/462): Loss: 1130.4785156250\n",
      "===> Epoch[17](280/462): Loss: 932.8826904297\n",
      "===> Epoch[17](290/462): Loss: 1359.1357421875\n",
      "===> Epoch[17](300/462): Loss: 1316.5684814453\n",
      "===> Epoch[17](310/462): Loss: 1819.2961425781\n",
      "===> Epoch[17](320/462): Loss: 999.1280517578\n",
      "===> Epoch[17](330/462): Loss: 1881.8942871094\n",
      "===> Epoch[17](340/462): Loss: 1944.0084228516\n",
      "===> Epoch[17](350/462): Loss: 1233.7116699219\n",
      "===> Epoch[17](360/462): Loss: 1085.1030273438\n",
      "===> Epoch[17](370/462): Loss: 1151.5219726562\n",
      "===> Epoch[17](380/462): Loss: 1467.2966308594\n",
      "===> Epoch[17](390/462): Loss: 1342.0754394531\n",
      "===> Epoch[17](400/462): Loss: 1694.5881347656\n",
      "===> Epoch[17](410/462): Loss: 1199.6455078125\n",
      "===> Epoch[17](420/462): Loss: 990.4196777344\n",
      "===> Epoch[17](430/462): Loss: 1355.3182373047\n",
      "===> Epoch[17](440/462): Loss: 976.6630859375\n",
      "===> Epoch[17](450/462): Loss: 948.6691894531\n",
      "===> Epoch[17](460/462): Loss: 1638.6611328125\n",
      "Checkpoint saved to checkpoint/model_epoch_17.pth\n",
      "Epoch = 18, lr = 0.00010000000000000003\n",
      "===> Epoch[18](10/462): Loss: 902.6907958984\n",
      "===> Epoch[18](20/462): Loss: 1097.1267089844\n",
      "===> Epoch[18](30/462): Loss: 1745.4079589844\n",
      "===> Epoch[18](40/462): Loss: 1095.8184814453\n",
      "===> Epoch[18](50/462): Loss: 1337.7397460938\n",
      "===> Epoch[18](60/462): Loss: 2371.4628906250\n",
      "===> Epoch[18](70/462): Loss: 1362.0582275391\n",
      "===> Epoch[18](80/462): Loss: 1298.7734375000\n",
      "===> Epoch[18](90/462): Loss: 1408.4235839844\n",
      "===> Epoch[18](100/462): Loss: 945.3509521484\n",
      "===> Epoch[18](110/462): Loss: 1255.9968261719\n",
      "===> Epoch[18](120/462): Loss: 650.8527832031\n",
      "===> Epoch[18](130/462): Loss: 1263.9934082031\n",
      "===> Epoch[18](140/462): Loss: 1238.0722656250\n",
      "===> Epoch[18](150/462): Loss: 1212.0783691406\n",
      "===> Epoch[18](160/462): Loss: 1422.0070800781\n",
      "===> Epoch[18](170/462): Loss: 803.0224609375\n",
      "===> Epoch[18](180/462): Loss: 1665.8369140625\n",
      "===> Epoch[18](190/462): Loss: 1089.5091552734\n",
      "===> Epoch[18](200/462): Loss: 936.5052490234\n",
      "===> Epoch[18](210/462): Loss: 1090.5129394531\n",
      "===> Epoch[18](220/462): Loss: 989.6826782227\n",
      "===> Epoch[18](230/462): Loss: 796.4088134766\n",
      "===> Epoch[18](240/462): Loss: 1515.9344482422\n",
      "===> Epoch[18](250/462): Loss: 980.9333496094\n",
      "===> Epoch[18](260/462): Loss: 1622.8774414062\n",
      "===> Epoch[18](270/462): Loss: 1024.3789062500\n",
      "===> Epoch[18](280/462): Loss: 809.3095703125\n",
      "===> Epoch[18](290/462): Loss: 1018.4751586914\n",
      "===> Epoch[18](300/462): Loss: 1295.2824707031\n",
      "===> Epoch[18](310/462): Loss: 1107.9566650391\n",
      "===> Epoch[18](320/462): Loss: 852.8347778320\n",
      "===> Epoch[18](330/462): Loss: 884.1450195312\n",
      "===> Epoch[18](340/462): Loss: 701.3328857422\n",
      "===> Epoch[18](350/462): Loss: 1278.0007324219\n",
      "===> Epoch[18](360/462): Loss: 844.6744384766\n",
      "===> Epoch[18](370/462): Loss: 990.0703125000\n",
      "===> Epoch[18](380/462): Loss: 1098.4965820312\n",
      "===> Epoch[18](390/462): Loss: 1291.6979980469\n",
      "===> Epoch[18](400/462): Loss: 768.5458984375\n",
      "===> Epoch[18](410/462): Loss: 880.9968261719\n",
      "===> Epoch[18](420/462): Loss: 754.3264160156\n",
      "===> Epoch[18](430/462): Loss: 792.0135498047\n",
      "===> Epoch[18](440/462): Loss: 1455.3745117188\n",
      "===> Epoch[18](450/462): Loss: 912.6071777344\n",
      "===> Epoch[18](460/462): Loss: 1401.5307617188\n",
      "Checkpoint saved to checkpoint/model_epoch_18.pth\n",
      "Epoch = 19, lr = 0.00010000000000000003\n",
      "===> Epoch[19](10/462): Loss: 1454.4042968750\n",
      "===> Epoch[19](20/462): Loss: 738.7259521484\n",
      "===> Epoch[19](30/462): Loss: 1339.6840820312\n",
      "===> Epoch[19](40/462): Loss: 922.6471557617\n",
      "===> Epoch[19](50/462): Loss: 1168.5156250000\n",
      "===> Epoch[19](60/462): Loss: 1146.0134277344\n",
      "===> Epoch[19](70/462): Loss: 1105.2287597656\n",
      "===> Epoch[19](80/462): Loss: 1716.4645996094\n",
      "===> Epoch[19](90/462): Loss: 875.6342773438\n",
      "===> Epoch[19](100/462): Loss: 1371.5451660156\n",
      "===> Epoch[19](110/462): Loss: 1079.8143310547\n",
      "===> Epoch[19](120/462): Loss: 1171.5568847656\n",
      "===> Epoch[19](130/462): Loss: 1352.3999023438\n",
      "===> Epoch[19](140/462): Loss: 1136.2316894531\n",
      "===> Epoch[19](150/462): Loss: 1651.8074951172\n",
      "===> Epoch[19](160/462): Loss: 1092.6485595703\n",
      "===> Epoch[19](170/462): Loss: 696.1620483398\n",
      "===> Epoch[19](180/462): Loss: 2447.1298828125\n",
      "===> Epoch[19](190/462): Loss: 2386.5671386719\n",
      "===> Epoch[19](200/462): Loss: 1043.9173583984\n",
      "===> Epoch[19](210/462): Loss: 1698.7530517578\n",
      "===> Epoch[19](220/462): Loss: 959.2670288086\n",
      "===> Epoch[19](230/462): Loss: 1037.8999023438\n",
      "===> Epoch[19](240/462): Loss: 1043.0427246094\n",
      "===> Epoch[19](250/462): Loss: 3317.2480468750\n",
      "===> Epoch[19](260/462): Loss: 2510.7070312500\n",
      "===> Epoch[19](270/462): Loss: 1057.2678222656\n",
      "===> Epoch[19](280/462): Loss: 1387.9941406250\n",
      "===> Epoch[19](290/462): Loss: 699.5480957031\n",
      "===> Epoch[19](300/462): Loss: 884.3229980469\n",
      "===> Epoch[19](310/462): Loss: 1252.5540771484\n",
      "===> Epoch[19](320/462): Loss: 767.8107910156\n",
      "===> Epoch[19](330/462): Loss: 2079.9179687500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[19](340/462): Loss: 1189.7473144531\n",
      "===> Epoch[19](350/462): Loss: 991.3833007812\n",
      "===> Epoch[19](360/462): Loss: 1510.6101074219\n",
      "===> Epoch[19](370/462): Loss: 1469.0603027344\n",
      "===> Epoch[19](380/462): Loss: 2487.9348144531\n",
      "===> Epoch[19](390/462): Loss: 1596.5756835938\n",
      "===> Epoch[19](400/462): Loss: 1601.6894531250\n",
      "===> Epoch[19](410/462): Loss: 938.0840454102\n",
      "===> Epoch[19](420/462): Loss: 1691.3320312500\n",
      "===> Epoch[19](430/462): Loss: 1399.6654052734\n",
      "===> Epoch[19](440/462): Loss: 1256.7355957031\n",
      "===> Epoch[19](450/462): Loss: 931.3432617188\n",
      "===> Epoch[19](460/462): Loss: 904.8264160156\n",
      "Checkpoint saved to checkpoint/model_epoch_19.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "        train(training_data_loader, optimizer, model, criterion, epoch)\n",
    "        save_checkpoint(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (residual_layer): Sequential(\n",
      "    (0): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Conv_ReLU_Block(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (input): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (output): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that takes in a .mp4 video file and applies intrinsic matrix and distortion coefficients to undistort a video.  It also preserves the sound. it uses ffmpeg for some processing as well as opencv cv2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colorization function\n",
    "# We'll reuse the Cb and Cr channels from bicubic interpolation\n",
    "def colorize(y, ycbcr): \n",
    "    img = np.zeros((y.shape[0], y.shape[1], 3), np.uint8)\n",
    "    img[:,:,0] = y\n",
    "    img[:,:,1] = ycbcr[:,:,1]\n",
    "    img[:,:,2] = ycbcr[:,:,2]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superres_mp4(infile, outfile, model, factor=1.0,display=True,bitrate= \"12000k\",errorfile = None):\n",
    "    \n",
    "    model = model.cuda()\n",
    "    #torch.set_grad_enabled(False)\n",
    "    #model.eval()\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(infile))\n",
    "    \n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    success_flag = False\n",
    "    \n",
    "    print(\"Original File:\", str(infile))\n",
    "    print(\"frames=\",length,\"\\nwidth=\",width,\"\\nheight=\",height,\"\\nfps=\",fps)\n",
    "    \n",
    "    \n",
    "\n",
    "    new_height = int(height*factor)\n",
    "    new_width = int(width*factor)\n",
    "    \n",
    "    print(\"\\nProcess File:\", str(outfile))\n",
    "    print(\"factor:\",factor,\"\\nwidth=\",new_width, \"\\nheight=\",new_height,\"\\nbitrate=\",bitrate)\n",
    "    \n",
    "    \n",
    "\n",
    "    dimension = '{}x{}'.format(new_width, new_height)  #ffmpeg uses bicubic as default scaling alg\n",
    "    f_format = 'bgr24' # remember OpenCV uses bgr format\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    command = ['ffmpeg',\n",
    "            '-y',\n",
    "            '-f', 'rawvideo',\n",
    "            '-vcodec','rawvideo',\n",
    "            '-s', dimension,\n",
    "            '-pix_fmt', 'bgr24',\n",
    "            '-r', str(fps),\n",
    "            '-i', '-',\n",
    "            '-i', str(infile),\n",
    "            '-c:v', 'h264',\n",
    "            '-c:a', 'aac',\n",
    "\n",
    "            '-map','0:v:0',\n",
    "            '-map','1:a:0',\n",
    "            '-shortest',\n",
    "            '-b:v', bitrate, \n",
    "            str(outfile) ]\n",
    "\n",
    "\n",
    "    if errorfile is not None:\n",
    "        ef = open(error_file,\"w+\")\n",
    "        p = sp.Popen(command, stdin=sp.PIPE, stderr=ef)\n",
    "    else:\n",
    "        p = sp.Popen(command, stdin=sp.PIPE)\n",
    "\n",
    "    # Full processing with a stream instead of a temp file for video\n",
    "    pbar = tqdm(total=length)\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            \n",
    "            if (factor != 1.0):\n",
    "                frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "            im_b_ycbcr = cv2.cvtColor(frame, cv2.COLOR_BGR2YCR_CB)\n",
    "            im_b_y = im_b_ycbcr[:,:,0].astype(float)\n",
    "            im_input = im_b_y/255.\n",
    "            im_input = Variable(torch.from_numpy(im_input).float()).view(1, -1, im_input.shape[0], im_input.shape[1])\n",
    "            im_input = im_input.cuda()\n",
    "            out = model(im_input)\n",
    "\n",
    "            out = out.cpu()\n",
    "            im_h_y = out.data[0].numpy().astype(np.float32)\n",
    "            im_h_y = im_h_y * 255.\n",
    "            im_h_y[im_h_y < 0] = 0\n",
    "            im_h_y[im_h_y > 255.] = 255.\n",
    "            im_h_y = im_h_y[0,:,:]\n",
    "\n",
    "            im_h = colorize(im_h_y, im_b_ycbcr)\n",
    "            \n",
    "                \n",
    "\n",
    "            p.stdin.write(im_h.tobytes())\n",
    "\n",
    "\n",
    "            if display:\n",
    "                cv2.imshow('Processed',im_h)\n",
    "                time.sleep(10)\n",
    "                #cv2.imshow('Orig',frame)\n",
    "            pbar.update(1)\n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                success_flag = False\n",
    "                break\n",
    "        # Break the loop\n",
    "        else:\n",
    "            success_flag = True\n",
    "            break\n",
    "    # When everything done, release the video capture object\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    p.stdin.close()\n",
    "    p.wait()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return success_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"/media/SSD/superres/super8/super8_best_from_mp2.mp4\"\n",
    "outfile = \"/media/SSD/superres/super8test2.mp4\"\n",
    "error_file = \"/media/SSD/superres/error.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/media/SSD/conda_env/superres/lib/python3.8/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "\n",
    "model = torch.load(\"/media/SSD/superres/pytorch-vdsr/model/model_epoch_50.pth\")[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7195 [00:00<16:24,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File: /media/SSD/superres/super8/super8_best_from_mp2.mp4\n",
      "frames= 7195 \n",
      "width= 720 \n",
      "height= 480 \n",
      "fps= 59.94005994005994\n",
      "\n",
      "Process File: /media/SSD/superres/super8test2.mp4\n",
      "factor: 1.0 \n",
      "width= 720 \n",
      "height= 480 \n",
      "bitrate= 4000k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7195/7195 [10:59<00:00, 10.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superres_mp4(infile, outfile, model, factor=1.0,display=False,bitrate= \"4000k\",errorfile = error_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def superres_parallel_mp4(infile, outfile, model, factor=1.0,display=True,bitrate= \"12000k\",errorfile = None):\n",
    "\n",
    "    class DummyTask:\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "        def ready(self):\n",
    "            return True\n",
    "        def get(self):\n",
    "            return self.data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    model = model.cpu()\n",
    "    #torch.set_grad_enabled(False)\n",
    "    #model.eval()\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(infile))\n",
    "    \n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    success_flag = False\n",
    "    \n",
    "    print(\"Original File:\", str(infile))\n",
    "    print(\"frames=\",length,\"\\nwidth=\",width,\"\\nheight=\",height,\"\\nfps=\",fps)\n",
    "    \n",
    "    \n",
    "\n",
    "    new_height = int(height*factor)\n",
    "    new_width = int(width*factor)\n",
    "    \n",
    "    print(\"\\nProcess File:\", str(outfile))\n",
    "    print(\"factor:\",factor,\"\\nwidth=\",new_width, \"\\nheight=\",new_height,\"\\nbitrate=\",bitrate)\n",
    "    \n",
    "    \n",
    "\n",
    "    dimension = '{}x{}'.format(new_width, new_height)  #ffmpeg uses bicubic as default scaling alg\n",
    "    f_format = 'bgr24' # remember OpenCV uses bgr format\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    command = ['ffmpeg',\n",
    "            '-y',\n",
    "            '-f', 'rawvideo',\n",
    "            '-vcodec','rawvideo',\n",
    "            '-s', dimension,\n",
    "            '-pix_fmt', 'bgr24',\n",
    "            '-r', str(fps),\n",
    "            '-i', '-',\n",
    "            '-i', str(infile),\n",
    "            '-c:v', 'h264',\n",
    "            '-c:a', 'aac',\n",
    "torc\n",
    "            '-map','0:v:0',\n",
    "            '-map','1:a:0',\n",
    "            '-shortest',\n",
    "            '-b:v', bitrate, \n",
    "            str(outfile) ]\n",
    "\n",
    "\n",
    "    if errorfile is not None:\n",
    "        ef = open(error_file,\"w+\")\n",
    "        p = sp.Popen(command, stdin=sp.PIPE, stderr=ef)\n",
    "    else:\n",
    "        p = sp.Popen(command, stdin=sp.PIPE)   \n",
    "    \n",
    "    \n",
    " \n",
    "    def process_frame(frame, t0):\n",
    "        \n",
    "        if (factor != 1.0):\n",
    "            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "        im_b_ycbcr = cv2.cvtColor(frame, cv2.COLOR_BGR2YCR_CB)\n",
    "        im_b_y = im_b_ycbcr[:,:,0].astype(float)\n",
    "        im_input = im_b_y/255.\n",
    "        im_input = Variable(torch.from_numpy(im_input).float()).view(1, -1, im_input.shape[0], im_input.shape[1])\n",
    "        #im_input = im_input.cuda()\n",
    "        out = model(im_input)\n",
    "\n",
    "        #out = out.cpu()\n",
    "        im_h_y = out.data[0].numpy().astype(np.float32)\n",
    "        im_h_y = im_h_y * 255.\n",
    "        im_h_y[im_h_y < 0] = 0\n",
    "        im_h_y[im_h_y > 255.] = 255.\n",
    "        im_h_y = im_h_y[0,:,:]\n",
    "\n",
    "        im_h = colorize(im_h_y, im_b_ycbcr)        \n",
    "        \n",
    "        \n",
    "        return im_h, t0\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    threadn = cv2.getNumberOfCPUs()\n",
    "    pool = ThreadPool(processes = threadn)\n",
    "    pending = deque()\n",
    "\n",
    "    threaded_mode = True\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        while len(pending) > 0 and pending[0].ready():\n",
    "            res, t0 = pending.popleft().get()\n",
    "            p.stdin.write(res.tobytes())\n",
    "            \n",
    "            \n",
    "            cv2.imshow('threaded video', res)\n",
    "        if len(pending) < threadn:\n",
    "            _ret, frame = cap.read()\n",
    "            t = 0\n",
    "            \n",
    "            last_frame_time = t\n",
    "            if threaded_mode:\n",
    "                task = pool.apply_async(process_frame, (frame.copy(), t))\n",
    "            else:\n",
    "                task = DummyTask(process_frame(frame, t))\n",
    "            pending.append(task)\n",
    "        ch = cv2.waitKey(1)\n",
    "        if ch == ord(' '):\n",
    "            threaded_mode = not threaded_mode\n",
    "        if ch == 27:\n",
    "            break\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    p.stdin.close()\n",
    "    p.wait()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File: /media/SSD/superres/sup8snip.mp4\n",
      "frames= 1797 \n",
      "width= 720 \n",
      "height= 480 \n",
      "fps= 29.97002997002997\n",
      "\n",
      "Process File: /media/SSD/superres/super8test.mp4\n",
      "factor: 1.0 \n",
      "width= 720 \n",
      "height= 480 \n",
      "bitrate= 4000k\n"
     ]
    }
   ],
   "source": [
    "superres_parallel_mp4(infile, outfile, model, factor=1.0,display=False,bitrate= \"4000k\",errorfile = error_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (residual_layer): Sequential(\n",
       "    (0): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (input): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (output): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infolder = Path(\"to_do_videos\")\n",
    "outfolder = Path(\"undistorted_videos\")\n",
    "completefolder = Path(\"raw_videos\")\n",
    "\n",
    "outfolder.mkdir(exist_ok=True)\n",
    "completefolder.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in infolder.iterdir():\n",
    "    \n",
    "\n",
    "    undistort_outfile = outfolder/(\"undistort\"+filename.name)\n",
    "    \n",
    "    retval = undistort_mp4(infile=filename, outfile=undistort_outfile,\n",
    "                           intrinsic_matrix=im, distortion_coefficients=dc,\n",
    "                           crop=True,display=False,bitrate= \"12000k\",errorfile = None)   \n",
    "    \n",
    "    if retval:\n",
    "        #move the source file if successful\n",
    "        completefile = completefolder/filename.name\n",
    "        filename.rename(completefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
